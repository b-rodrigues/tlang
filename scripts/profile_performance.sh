#!/usr/bin/env bash
# scripts/profile_performance.sh
# Performance profiling for T's Arrow backend operations.
# Runs the performance test suite and reports timing results.
#
# Usage:
#   ./scripts/profile_performance.sh          # Run all profiling tests
#   ./scripts/profile_performance.sh --quick   # Run only 10k-row tests
#
# Prerequisites:
#   - OCaml toolchain (dune, ocaml) available via `nix develop`
#   - Project built: `dune build`

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"

cd "$PROJECT_ROOT"

# ---------------------------------------------------------------------------
# Configuration
# ---------------------------------------------------------------------------
QUICK_MODE=false
if [[ "${1:-}" == "--quick" ]]; then
  QUICK_MODE=true
fi

OUTPUT_DIR="$PROJECT_ROOT/docs"
RESULTS_FILE="$OUTPUT_DIR/performance_analysis.md"

# ---------------------------------------------------------------------------
# Build
# ---------------------------------------------------------------------------
echo "=== Building T ==="
if ! dune build 2>&1; then
  echo "✗ Build failed. Fix build errors before profiling."
  exit 1
fi
echo "✓ Build complete"
echo ""

# ---------------------------------------------------------------------------
# Run performance tests and capture output
# ---------------------------------------------------------------------------
echo "=== Running Performance Tests ==="
TEST_OUTPUT=$(dune exec tests/test_runner.exe 2>&1 || true)

# Extract Arrow Performance section
PERF_OUTPUT=$(echo "$TEST_OUTPUT" | sed -n '/Arrow Performance/,/=== Results/p' | head -n -1)

if [[ -z "$PERF_OUTPUT" ]]; then
  echo "⚠ No Arrow Performance output found in test results."
  echo "  Make sure test_arrow_performance.ml is registered in test_runner.ml."
  exit 1
fi

echo "$PERF_OUTPUT"
echo ""

# ---------------------------------------------------------------------------
# Extract timing data
# ---------------------------------------------------------------------------
echo "=== Extracting Timing Data ==="

extract_time() {
  local label="$1"
  echo "$PERF_OUTPUT" | grep -oP "$label.*?\((\K[0-9.]+)(?=s\))" | head -1
}

# 10k timings
T_PROJECT_10K=$(extract_time "Project 2 columns from 10k")
T_FILTER_10K=$(extract_time "Filter 10k rows")
T_SUM_10K=$(extract_time "Sum 10k rows")
T_GROUPBY_10K=$(extract_time "Group-by 10k rows")
T_GROUPAGG_10K=$(extract_time "Group aggregate mean 10k rows")

# 100k timings
T_PROJECT_100K=$(extract_time "Project 100k rows")
T_SUM_100K=$(extract_time "Sum 100k rows")
T_GROUPBY_100K=$(extract_time "Group-by 100k rows")
T_GROUPAGG_100K=$(extract_time "Group aggregate sum 100k rows")

# 1M timings
T_PROJECT_1M=$(extract_time "Project 1M rows")
T_SUM_1M=$(extract_time "Sum 1M rows")
T_MEAN_1M=$(extract_time "Mean 1M rows")
T_GROUPBY_1M=$(extract_time "Group-by 1M rows")
T_GROUPAGG_1M=$(extract_time "Group aggregate mean 1M rows")

# Math timings (100k)
T_SQRT_100K=$(extract_time "sqrt_column on 100k rows")
T_ABS_100K=$(extract_time "abs_column on 100k rows")
T_CMP_100K=$(extract_time "compare_column_scalar on 100k rows")

# ---------------------------------------------------------------------------
# Generate performance analysis document
# ---------------------------------------------------------------------------
echo "=== Generating Performance Analysis ==="

cat > "$RESULTS_FILE" << 'HEADER'
# Performance Analysis

> Auto-generated by `scripts/profile_performance.sh`

---

## Test Environment

HEADER

echo "- **Date**: $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> "$RESULTS_FILE"
echo "- **Platform**: $(uname -s) $(uname -m)" >> "$RESULTS_FILE"
echo "- **OCaml**: $(ocaml --version 2>/dev/null || echo 'N/A')" >> "$RESULTS_FILE"

cat >> "$RESULTS_FILE" << 'MIDDLE'

---

## Timing Results

### 10k Rows (100 groups)

| Operation | Time (s) |
|-----------|----------|
MIDDLE

printf "| Project 2 columns | %s |\n" "${T_PROJECT_10K:-N/A}" >> "$RESULTS_FILE"
printf "| Filter rows | %s |\n" "${T_FILTER_10K:-N/A}" >> "$RESULTS_FILE"
printf "| Sum column | %s |\n" "${T_SUM_10K:-N/A}" >> "$RESULTS_FILE"
printf "| Group-by | %s |\n" "${T_GROUPBY_10K:-N/A}" >> "$RESULTS_FILE"
printf "| Group aggregate (mean) | %s |\n" "${T_GROUPAGG_10K:-N/A}" >> "$RESULTS_FILE"

cat >> "$RESULTS_FILE" << 'SECTION100K'

### 100k Rows (1000 groups)

| Operation | Time (s) |
|-----------|----------|
SECTION100K

printf "| Project 2 columns | %s |\n" "${T_PROJECT_100K:-N/A}" >> "$RESULTS_FILE"
printf "| Sum column | %s |\n" "${T_SUM_100K:-N/A}" >> "$RESULTS_FILE"
printf "| Group-by | %s |\n" "${T_GROUPBY_100K:-N/A}" >> "$RESULTS_FILE"
printf "| Group aggregate (sum) | %s |\n" "${T_GROUPAGG_100K:-N/A}" >> "$RESULTS_FILE"
printf "| sqrt (vectorized) | %s |\n" "${T_SQRT_100K:-N/A}" >> "$RESULTS_FILE"
printf "| abs (vectorized) | %s |\n" "${T_ABS_100K:-N/A}" >> "$RESULTS_FILE"
printf "| compare scalar | %s |\n" "${T_CMP_100K:-N/A}" >> "$RESULTS_FILE"

cat >> "$RESULTS_FILE" << 'SECTION1M'

### 1M Rows (10000 groups)

| Operation | Time (s) |
|-----------|----------|
SECTION1M

printf "| Project 2 columns | %s |\n" "${T_PROJECT_1M:-N/A}" >> "$RESULTS_FILE"
printf "| Sum column | %s |\n" "${T_SUM_1M:-N/A}" >> "$RESULTS_FILE"
printf "| Mean column | %s |\n" "${T_MEAN_1M:-N/A}" >> "$RESULTS_FILE"
printf "| Group-by | %s |\n" "${T_GROUPBY_1M:-N/A}" >> "$RESULTS_FILE"
printf "| Group aggregate (mean) | %s |\n" "${T_GROUPAGG_1M:-N/A}" >> "$RESULTS_FILE"

cat >> "$RESULTS_FILE" << 'FOOTER'

---

## Analysis

### Scaling Behavior

Operations should scale approximately linearly with row count:
- 10x rows → ~10x time for columnar operations
- Group-by scaling depends on group cardinality

### Hot Paths

The most time-critical operations for large datasets are:
1. **Group-by + aggregation**: Dominates pipeline execution time for grouped summarizations
2. **Filter**: Boolean mask construction + row extraction
3. **CSV reading**: I/O bound for large files; Arrow native reader provides significant speedup

### Optimization Opportunities

- **Materialization avoidance**: After `mutate()`, the native Arrow handle is dropped. Lazy evaluation could defer materialization.
- **Column pruning**: Pipelines that only use a subset of columns could skip loading unused columns from CSV.
- **Parallel execution**: Arrow Compute supports multi-threaded execution via Rayon; not yet exposed through FFI.

---

## Targets

See [docs/performance.md](performance.md) for detailed performance expectations and the Arrow backend architecture overview.
FOOTER

echo "✓ Performance analysis written to: $RESULTS_FILE"
echo ""
echo "=== Profile Complete ==="
