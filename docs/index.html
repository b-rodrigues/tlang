<!DOCTYPE html>
<html>
<head>
  <title>T Programming Language</title>
</head>
<body bgcolor="#f5f5dc" text="#000000" link="#0000ee" vlink="#551a8b" alink="#ff0000">

  <center>
    <h1><font face="Courier New">T — A Language for Tabular Data and Human–LLM Collaboration</font></h1>
    <hr width="80%">
  </center>

  <font face="Courier New" size="3">

  <p>
    <b>T</b> is an experimental programming language for declarative, functional manipulation
    of tabular data. Inspired by R’s tidyverse and OCaml’s semantic rigor, T is designed
    to make data analysis <b>explicit, inspectable, and pipeline-oriented</b>.
  </p>

  <p>
    Unlike traditional scripting languages, T is built from the ground up to support
    <b>human–LLM collaborative programming</b>, where humans specify intent and constraints,
    and language tools (including LLMs) generate localized, mechanical code.
  </p>

  <p><b>Status:</b> Pre-alpha. Actively designed and implemented.</p>

  <hr>

  <h2><font face="Courier New">Documentation</font></h2>
  <ul>
    <li><a href="language_overview.html">Language Overview</a> — types, syntax, functions, and standard library</li>
    <li><a href="data_manipulation_examples.html">Data Manipulation Examples</a> — practical examples with core data verbs</li>
    <li><a href="pipeline_tutorial.html">Pipeline Tutorial</a> — step-by-step guide to T's pipeline model</li>
  </ul>

  <hr>

  <h2><font face="Courier New">Design Goals</font></h2>
  <ul>
    <li>Data analysis as explicit pipelines</li>
    <li>First-class tabular data (DataFrame-centric)</li>
    <li>Expression-oriented, functional style</li>
    <li>Explicit semantics (no hidden rules, no implicit NA propagation)</li>
    <li>Minimal OCaml core, extensible via packages</li>
    <li>Deterministic execution and inspectable errors</li>
    <li>REPL-first exploratory workflow</li>
    <li>LLM-friendly structure and tooling</li>
  </ul>

  <hr>

  <h2><font face="Courier New">LLM-Native by Design</font></h2>

  <p>
    T treats large language models as <b>first-class collaborators</b>, not magic code generators.
    The language and tooling are designed to make LLM-generated code:
  </p>

  <ul>
    <li>Local rather than global</li>
    <li>Constrained rather than free-form</li>
    <li>Inspectable rather than opaque</li>
    <li>Correctable rather than brittle</li>
  </ul>

  <p>
    Humans define intent, assumptions, and invariants. LLMs generate localized code.
    T enforces semantics and correctness.
  </p>

  <hr>

  <h2><font face="Courier New">Intent Blocks</font></h2>

  <p>
    T supports <b>intent blocks</b>: structured comments that encode analytical goals,
    assumptions, and checks in a machine-readable way.
  </p>

  <pre>
-- intent:
-- goal: "Estimate approval as a function of age and income"
-- assumptions:
--   - age is approximately linear
--   - missing income is non-random
-- checks:
--   - no negative income
--   - at least 100 observations per group
  </pre>

  <p>
    Intent blocks are preserved by tooling, version-controlled with code, and used
    as stable regeneration boundaries for LLM-assisted workflows.
  </p>

  <hr>

  <h2><font face="Courier New">Pipelines</font></h2>

  <p>
    Pipelines are T’s core execution model. Each pipeline is a DAG of named nodes with
    explicit dependencies, cacheable results, and inspectable outputs.
  </p>

  <pre>
pipeline analysis {
  raw = { read_csv("data.csv") }

  cleaned = {
    raw |> filter(age > 18)
        |> mutate(income_k = income / 1000)
  }

  model = {
    cleaned |> lm(approval ~ age + income_k)
  }
}
  </pre>

  <p>
    Pipelines enable local reasoning, reproducibility, and safe regeneration of individual
    steps without rewriting entire scripts.
  </p>

  <hr>

  <h2><font face="Courier New">Language Features</font></h2>

  <ul>
    <li>R-style lambdas: <code>\(x) x + 1</code></li>
    <li>Conditional pipe operator: <code>|></code> (short-circuits on error)</li>
    <li>Maybe-pipe operator: <code>?|></code> (forwards errors for recovery)</li>
    <li>Python-style comprehensions: <code>[x * x for x in xs if x > 2]</code></li>
    <li>Python-style dictionaries: <code>{name: "Alice", age: 30}</code></li>
    <li>Errors as values, not exceptions</li>
    <li>Explicit, typed missing values</li>
  </ul>

  <hr>

  <h2><font face="Courier New">Pipe Operators</font></h2>

  <p>
    T provides two pipe operators with different error-handling semantics:
  </p>

  <h3><font face="Courier New">Conditional Pipe: <code>|></code></font></h3>
  <p>
    The standard pipe passes the left-hand value as the first argument to the right-hand
    function. If the left-hand value is an error, the pipeline <b>short-circuits</b> and
    the error is returned without calling the function.
  </p>
  <pre>
5 |> double                -- 10
error("boom") |> double    -- Error (short-circuited)
  </pre>

  <h3><font face="Courier New">Maybe-Pipe: <code>?|></code></font></h3>
  <p>
    The maybe-pipe <b>always</b> forwards the left-hand value — including errors —
    to the right-hand function. This enables explicit error recovery patterns.
  </p>
  <pre>
-- Recover from errors:
handle = \(x) if (is_error(x)) "recovered" else x
error("boom") ?|> handle           -- "recovered"

-- Chain recovery with normal processing:
recovery = \(x) if (is_error(x)) 0 else x
increment = \(x) x + 1
error("fail") ?|> recovery |> increment  -- 1
  </pre>

  <p>
    Together, <code>|></code> and <code>?|></code> enable
    <b>Railway-Oriented Programming</b> in T: errors flow through pipelines as
    explicit values, and recovery logic is composable.
  </p>

  <hr>

  <h2><font face="Courier New">Numerical Backend</font></h2>

  <p>
    T’s numerical stack is layered:
  </p>

  <ul>
    <li><b>Tabular layer:</b> Apache Arrow for columnar data and interoperability</li>
    <li><b>Compute layer:</b> Owl for linear algebra, optimization, and statistics</li>
    <li><b>Fallback layer:</b> Selective C bindings (e.g. LAPACK, GSL) when needed</li>
  </ul>

  <p>
    This approach prioritizes fast development, explicit semantics, and safe defaults,
    while leaving room for future performance upgrades.
  </p>

  <hr>

  <h2><font face="Courier New">Standard Packages</font></h2>
  <ul>
    <li><b>core</b>: functional utilities</li>
    <li><b>stats</b>: statistical primitives</li>
    <li><b>colcraft</b>: DataFrame operations</li>
  </ul>

  <p>
    Packages are part of the standard library and loaded by default.
    Each function lives in its own file.
  </p>

  <hr>

  <h2><font face="Courier New">Alpha Roadmap</font></h2>

  <p>
    The alpha version of T targets a complete, end-to-end workflow:
  </p>

  <ul>
    <li>Stable core syntax and interpreter</li>
    <li>Arrow-backed DataFrames</li>
    <li>DAG-based pipelines with caching</li>
    <li>Core data verbs (<code>select</code>, <code>filter</code>, <code>group_by</code>, <code>summarize</code>)</li>
    <li>Basic statistics and modeling</li>
    <li>Intent blocks and tooling hooks</li>
    <li>REPL and CLI</li>
  </ul>

  <p>
    Performance tuning, GPUs, and distributed execution are explicitly out of scope for alpha.
  </p>

  <hr>

  <h2><font face="Courier New">Project Structure</font></h2>
  <pre>
.
├── flake.nix
├── ast.ml
├── parser.ml
├── lexer.ml
├── eval.ml
├── repl.ml
├── pipeline.ml
├── dataframe.ml
└── packages/
    ├── core/
    ├── stats/
    └── colcraft/
  </pre>

  <hr>

  <h2><font face="Courier New">Building</font></h2>
  <pre>
nix develop
t repl
  </pre>

  <hr>

  <h2><font face="Courier New">Contributing</font></h2>

  <p>
    Contributions focus on clarity, explicit semantics, and small, reviewable changes.
    Packages live in-repo during early development.
  </p>

  <hr>

  <p><b>License:</b> EUPL v1.2.</p>

  <center>
    <hr width="60%">
    <font size="2">
      Best viewed with a sense of curiosity.<br>
      <a href="https://github.com/b-rodrigues/tlang">View Source on GitHub</a>
    </font>
  </center>

  </font>
</body>
</html>
